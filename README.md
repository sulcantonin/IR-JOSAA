This repository presents our data on inverse rendering with light field camera

[Paper preprint (PDF)](paper-preprint.pdf) | [Visualisation 1](TBD) | [Visualisation 2](TBD) | [Visualisation 3](TBD) | [Visualisation 4](TBD) 

# Abstract 
We propose an inverse rendering model for light fields to recover surface normals, depth, reflectance and natural illumination. Our setting is fully uncalibrated, with the reflectance modeled with a spatially-constant Blinn-Phong model and illumination as an environment map. While previous work makes strong assumptions in this difficult scenario, focusing solely on specific types of objects like faces or imposing very strong priors, our approach leverages only the light field structure, where a solution consistent across all subaperture views is sought. The optimization is based primarily on shading, which is sensitive to fine geometric details which are propagated to the initial coarse depth map. Despite the problem being inherently ill-posed, we achieve encouraging results on synthetic as well as real-world data.

# Data 
ðŸ’ª TBD
